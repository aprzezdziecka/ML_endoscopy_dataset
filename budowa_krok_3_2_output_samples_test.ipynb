{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7780d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28aeaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_list(path):\n",
    "    output_root =path\n",
    "    X = []\n",
    "    y = []\n",
    "    l=[]\n",
    "        \n",
    "    label_to_index = {\n",
    "        'AVM': 0,\n",
    "        'Normal': 1,\n",
    "        'Ulcer': 2\n",
    "    }\n",
    "    print(label_to_index)\n",
    "    for root, _, files in os.walk(output_root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bmp\"): \n",
    "                input_path = os.path.join(root, file)\n",
    "\n",
    "                base, ext = os.path.splitext(file)\n",
    "                new_filename = f\"{base}{ext}\"\n",
    "                image = cv2.imread(input_path)\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label_to_index[new_filename.split(\"_\")[0]])\n",
    "                l.append(new_filename)\n",
    "    return X, y, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2301b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/balanced-sampling-between-classes-with-torchvision-dataloader/2703/2\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])  \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long) \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71226b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Transfer(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet50Transfer, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Freeze all layers (optional: you can unfreeze later for fine-tuning)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for name, param in self.base_model.named_parameters():\n",
    "            if \"layer4\" in name or \"layer3\" in name:  # Unfreeze only final block\n",
    "                param.requires_grad = True\n",
    "\n",
    "        in_features = self.base_model.fc.in_features  # Usually 2048\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4a55981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_full(model, train_loader, test_loader, save_path, epochs=15, learning_rate=0.001, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    print(f\"Using device: {device}\") \n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct, test_total = 0, 0\n",
    "        test_labels, test_predictions = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                test_labels.extend(labels.cpu().numpy())\n",
    "                test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        test_loss /= test_total\n",
    "        test_acc = test_correct / test_total\n",
    "        test_precision = precision_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_recall = recall_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_f1 = f1_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Test  Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save best model based on test loss\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            print(\"Best model updated!\")\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Best model saved as {save_path}'\") # rozszerzenie .pth\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_acc = correct / total\n",
    "    test_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    print(\"\\n Final Test Evaluation:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", test_conf_matrix)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, l = save_to_list(\"output_samples2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54c3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0070bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          \n",
    "    transforms.RandomRotation((-180,180)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  # do testów - bez zmian\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = ImageDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "class_counts = np.bincount(y)  \n",
    "class_weights = 1.0 / class_counts \n",
    "\n",
    "sample_weights_tr = [class_weights[label] for label in y_train]\n",
    "sample_weights_ts = [class_weights[label] for label in y_test]\n",
    "\n",
    "samplertr = WeightedRandomSampler(sample_weights_tr, num_samples= len(sample_weights_tr), replacement=True)\n",
    "#samplerts = WeightedRandomSampler(sample_weights_ts, num_samples= len(sample_weights_ts), replacement=True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler = samplertr)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1020d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 20/20 [00:05<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 0.7697, Acc: 0.6453, Precision: 0.6472, Recall: 0.6453, F1: 0.6461\n",
      "Test  Loss: 26.2028, Acc: 0.5865, Precision: 0.8362, Recall: 0.5865, F1: 0.6081\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 20/20 [00:05<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "Train Loss: 0.5192, Acc: 0.7865, Precision: 0.7873, Recall: 0.7865, F1: 0.7867\n",
      "Test  Loss: 3.0275, Acc: 0.7594, Precision: 0.7630, Recall: 0.7594, F1: 0.6950\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 20/20 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "Train Loss: 0.3817, Acc: 0.8475, Precision: 0.8454, Recall: 0.8475, F1: 0.8451\n",
      "Test  Loss: 0.5777, Acc: 0.7895, Precision: 0.8347, Recall: 0.7895, F1: 0.7978\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 20/20 [00:05<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "Train Loss: 0.3401, Acc: 0.8973, Precision: 0.8976, Recall: 0.8973, F1: 0.8974\n",
      "Test  Loss: 0.6681, Acc: 0.7444, Precision: 0.8340, Recall: 0.7444, F1: 0.7618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 20/20 [00:05<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "Train Loss: 0.2144, Acc: 0.9133, Precision: 0.9128, Recall: 0.9133, F1: 0.9129\n",
      "Test  Loss: 0.3524, Acc: 0.8571, Precision: 0.8891, Recall: 0.8571, F1: 0.8648\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "Train Loss: 0.2385, Acc: 0.9165, Precision: 0.9164, Recall: 0.9165, F1: 0.9165\n",
      "Test  Loss: 0.1767, Acc: 0.9098, Precision: 0.9285, Recall: 0.9098, F1: 0.9132\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "Train Loss: 0.1787, Acc: 0.9422, Precision: 0.9431, Recall: 0.9422, F1: 0.9423\n",
      "Test  Loss: 0.1517, Acc: 0.9323, Precision: 0.9334, Recall: 0.9323, F1: 0.9305\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 20/20 [00:05<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "Train Loss: 0.1842, Acc: 0.9358, Precision: 0.9371, Recall: 0.9358, F1: 0.9356\n",
      "Test  Loss: 0.1935, Acc: 0.9173, Precision: 0.9220, Recall: 0.9173, F1: 0.9179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 20/20 [00:05<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "Train Loss: 0.1512, Acc: 0.9518, Precision: 0.9528, Recall: 0.9518, F1: 0.9521\n",
      "Test  Loss: 0.1205, Acc: 0.9474, Precision: 0.9468, Recall: 0.9474, F1: 0.9470\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "Train Loss: 0.1037, Acc: 0.9679, Precision: 0.9678, Recall: 0.9679, F1: 0.9678\n",
      "Test  Loss: 0.1194, Acc: 0.9549, Precision: 0.9543, Recall: 0.9549, F1: 0.9542\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 20/20 [00:05<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "Train Loss: 0.0949, Acc: 0.9647, Precision: 0.9652, Recall: 0.9647, F1: 0.9647\n",
      "Test  Loss: 0.1308, Acc: 0.9474, Precision: 0.9493, Recall: 0.9474, F1: 0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 20/20 [00:05<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Train Loss: 0.1113, Acc: 0.9695, Precision: 0.9701, Recall: 0.9695, F1: 0.9694\n",
      "Test  Loss: 0.1242, Acc: 0.9474, Precision: 0.9481, Recall: 0.9474, F1: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "Train Loss: 0.1151, Acc: 0.9599, Precision: 0.9600, Recall: 0.9599, F1: 0.9599\n",
      "Test  Loss: 0.1138, Acc: 0.9624, Precision: 0.9641, Recall: 0.9624, F1: 0.9627\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "Train Loss: 0.0616, Acc: 0.9807, Precision: 0.9807, Recall: 0.9807, F1: 0.9807\n",
      "Test  Loss: 0.1105, Acc: 0.9549, Precision: 0.9556, Recall: 0.9549, F1: 0.9546\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 20/20 [00:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "Train Loss: 0.0788, Acc: 0.9679, Precision: 0.9679, Recall: 0.9679, F1: 0.9679\n",
      "Test  Loss: 0.0860, Acc: 0.9624, Precision: 0.9641, Recall: 0.9624, F1: 0.9627\n",
      "Best model updated!\n",
      "Best model saved as model_output_samples_25.04.pth'\n",
      "\n",
      " Final Test Evaluation:\n",
      "Accuracy: 0.9624, Precision: 0.9641, Recall: 0.9624, F1: 0.9627\n",
      "Confusion Matrix:\n",
      " [[25  1  0]\n",
      " [ 3 83  1]\n",
      " [ 0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50Transfer(num_classes=3)\n",
    "trained_model = train_and_evaluate_full(model, train_loader, test_loader, \"model_output_samples_25.04.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624d316",
   "metadata": {},
   "source": [
    "Do porównania model wytrenowany na zdjęciach z folderu output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df1ba03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVM': 0, 'Normal': 1, 'Ulcer': 2}\n"
     ]
    }
   ],
   "source": [
    "X, y, l = save_to_list(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583cda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "813f0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          \n",
    "    transforms.RandomRotation((-180,180)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  # do testów - bez zmian\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = ImageDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "class_counts = np.bincount(y)  \n",
    "class_weights = 1.0 / class_counts \n",
    "\n",
    "sample_weights_tr = [class_weights[label] for label in y_train]\n",
    "sample_weights_ts = [class_weights[label] for label in y_test]\n",
    "\n",
    "samplertr = WeightedRandomSampler(sample_weights_tr, num_samples= len(sample_weights_tr), replacement=True)\n",
    "#samplerts = WeightedRandomSampler(sample_weights_ts, num_samples= len(sample_weights_ts), replacement=True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler = samplertr)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a0aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 72/72 [00:16<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 0.4553, Acc: 0.8330, Precision: 0.8335, Recall: 0.8330, F1: 0.8329\n",
      "Test  Loss: 0.2959, Acc: 0.8864, Precision: 0.8981, Recall: 0.8864, F1: 0.8888\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 72/72 [00:16<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "Train Loss: 0.2395, Acc: 0.9182, Precision: 0.9182, Recall: 0.9182, F1: 0.9181\n",
      "Test  Loss: 0.1776, Acc: 0.9493, Precision: 0.9507, Recall: 0.9493, F1: 0.9483\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 72/72 [00:16<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "Train Loss: 0.1892, Acc: 0.9352, Precision: 0.9358, Recall: 0.9352, F1: 0.9353\n",
      "Test  Loss: 0.1682, Acc: 0.9331, Precision: 0.9407, Recall: 0.9331, F1: 0.9348\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 72/72 [00:16<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "Train Loss: 0.1259, Acc: 0.9565, Precision: 0.9566, Recall: 0.9565, F1: 0.9565\n",
      "Test  Loss: 0.1413, Acc: 0.9554, Precision: 0.9583, Recall: 0.9554, F1: 0.9560\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 72/72 [00:16<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "Train Loss: 0.1091, Acc: 0.9665, Precision: 0.9667, Recall: 0.9665, F1: 0.9665\n",
      "Test  Loss: 0.1210, Acc: 0.9594, Precision: 0.9618, Recall: 0.9594, F1: 0.9598\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 72/72 [00:16<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "Train Loss: 0.0853, Acc: 0.9761, Precision: 0.9762, Recall: 0.9761, F1: 0.9761\n",
      "Test  Loss: 0.0667, Acc: 0.9817, Precision: 0.9819, Recall: 0.9817, F1: 0.9818\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 72/72 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "Train Loss: 0.0694, Acc: 0.9761, Precision: 0.9761, Recall: 0.9761, F1: 0.9761\n",
      "Test  Loss: 0.0821, Acc: 0.9777, Precision: 0.9780, Recall: 0.9777, F1: 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 72/72 [00:16<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "Train Loss: 0.0477, Acc: 0.9835, Precision: 0.9835, Recall: 0.9835, F1: 0.9835\n",
      "Test  Loss: 0.0623, Acc: 0.9838, Precision: 0.9837, Recall: 0.9838, F1: 0.9837\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 72/72 [00:15<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "Train Loss: 0.0347, Acc: 0.9891, Precision: 0.9891, Recall: 0.9891, F1: 0.9891\n",
      "Test  Loss: 0.0751, Acc: 0.9797, Precision: 0.9800, Recall: 0.9797, F1: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 72/72 [00:15<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "Train Loss: 0.0348, Acc: 0.9900, Precision: 0.9900, Recall: 0.9900, F1: 0.9900\n",
      "Test  Loss: 0.0734, Acc: 0.9797, Precision: 0.9800, Recall: 0.9797, F1: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 72/72 [00:15<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "Train Loss: 0.0412, Acc: 0.9852, Precision: 0.9852, Recall: 0.9852, F1: 0.9852\n",
      "Test  Loss: 0.0695, Acc: 0.9797, Precision: 0.9800, Recall: 0.9797, F1: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 72/72 [00:16<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Train Loss: 0.0234, Acc: 0.9930, Precision: 0.9930, Recall: 0.9930, F1: 0.9930\n",
      "Test  Loss: 0.0675, Acc: 0.9797, Precision: 0.9800, Recall: 0.9797, F1: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 72/72 [00:15<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "Train Loss: 0.0392, Acc: 0.9856, Precision: 0.9856, Recall: 0.9856, F1: 0.9856\n",
      "Test  Loss: 0.0614, Acc: 0.9817, Precision: 0.9817, Recall: 0.9817, F1: 0.9817\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 72/72 [00:16<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "Train Loss: 0.0446, Acc: 0.9870, Precision: 0.9870, Recall: 0.9870, F1: 0.9870\n",
      "Test  Loss: 0.0814, Acc: 0.9777, Precision: 0.9781, Recall: 0.9777, F1: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 72/72 [00:15<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "Train Loss: 0.0438, Acc: 0.9865, Precision: 0.9865, Recall: 0.9865, F1: 0.9865\n",
      "Test  Loss: 0.0507, Acc: 0.9899, Precision: 0.9900, Recall: 0.9899, F1: 0.9898\n",
      "Best model updated!\n",
      "Best model saved as model_output_simple.pth'\n",
      "\n",
      " Final Test Evaluation:\n",
      "Accuracy: 0.9899, Precision: 0.9900, Recall: 0.9899, F1: 0.9898\n",
      "Confusion Matrix:\n",
      " [[ 96   4   0]\n",
      " [  0 322   1]\n",
      " [  0   0  70]]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50Transfer(num_classes=3)\n",
    "trained_model = train_and_evaluate_full(model, train_loader, test_loader, \"model_output_simple.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
