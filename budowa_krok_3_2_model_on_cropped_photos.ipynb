{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13739f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "#from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "#import shutil\n",
    "#import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499f22c",
   "metadata": {},
   "source": [
    "# Model resnet50 na danych z folderu cropped_out_50 z użyciem klasteryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVM': 0, 'Normal': 1, 'Ulcer': 2}\n"
     ]
    }
   ],
   "source": [
    "def save_to_list(path):\n",
    "    output_root = path\n",
    "    X = []\n",
    "    y = []\n",
    "    l=[]\n",
    "        \n",
    "    label_to_index = {\n",
    "        'AVM': 0,\n",
    "        'Normal': 1,\n",
    "        'Ulcer': 2\n",
    "    }\n",
    "    print(label_to_index)\n",
    "    for root, _, files in os.walk(output_root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bmp\"): \n",
    "                input_path = os.path.join(root, file)\n",
    "\n",
    "                base, ext = os.path.splitext(file)\n",
    "                new_filename = f\"{base}{ext}\"\n",
    "                image = cv2.imread(input_path)\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label_to_index[new_filename.split(\"_\")[0]])\n",
    "                l.append(new_filename)\n",
    "    return X, y, l\n",
    "\n",
    "X, y, l = save_to_list(\"cropped_out_50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3493c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/balanced-sampling-between-classes-with-torchvision-dataloader/2703/2\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])  \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long) \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd60d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Transfer(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet50Transfer, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Freeze all layers (optional: you can unfreeze later for fine-tuning)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for name, param in self.base_model.named_parameters():\n",
    "            if \"layer4\" in name or \"layer3\" in name:  # Unfreeze only final block\n",
    "                param.requires_grad = True\n",
    "\n",
    "        in_features = self.base_model.fc.in_features  # Usually 2048\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b460515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_full(model, train_loader, test_loader, save_path, epochs=15, learning_rate=0.001, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    print(f\"Using device: {device}\") \n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        train_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct, test_total = 0, 0\n",
    "        test_labels, test_predictions = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                test_labels.extend(labels.cpu().numpy())\n",
    "                test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        test_loss /= test_total\n",
    "        test_acc = test_correct / test_total\n",
    "        test_precision = precision_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_recall = recall_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_f1 = f1_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Test  Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save best model based on test loss\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            print(\"Best model updated!\")\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Best model saved as {save_path}'\") # rozszerzenie .pth\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_acc = correct / total\n",
    "    test_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    print(\"\\n Final Test Evaluation:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", test_conf_matrix)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23afd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          \n",
    "    transforms.RandomRotation((-180,180)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  # do testów - bez zmian\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def extract_image_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img_resized = cv2.resize(img, (224, 224))  \n",
    "        img_flattened = img_resized.flatten()  \n",
    "        features.append(img_flattened)\n",
    "    return np.array(features)\n",
    "\n",
    "image_features = extract_image_features(X) \n",
    "db = DBSCAN(eps=6.5, min_samples=5)\n",
    "clusters = db.fit_predict(image_features)\n",
    "\n",
    "# Podział na zbiory treningowy i testowy\n",
    "train_indices, temp_indices = train_test_split(range(len(X)), test_size=0.2, stratify=y, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, stratify=[y[i] for i in temp_indices], random_state=42)\n",
    "\n",
    "# Wybór danych dla poszczególnych zbiorów\n",
    "train_images = [X[i] for i in train_indices]\n",
    "train_labels = [y[i] for i in train_indices]\n",
    "val_images = [X[i] for i in val_indices]\n",
    "val_labels = [y[i] for i in val_indices]\n",
    "test_images = [X[i] for i in test_indices]\n",
    "test_labels = [y[i] for i in test_indices]\n",
    "\n",
    "\n",
    "class_counts = np.bincount(train_labels)\n",
    "weights = 1. / class_counts  # Wagi odwrotności częstotliwości\n",
    "sample_weights = np.array([weights[label] for label in train_labels])\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_dataset = ImageDataset(train_images, train_labels, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "\n",
    "test_dataset = ImageDataset(test_images, test_labels, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3223296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alapr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 83/83 [00:13<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Loss: 0.5586, Acc: 0.7759, Precision: 0.7807, Recall: 0.7759, F1: 0.7764\n",
      "Test  Loss: 0.4032, Acc: 0.7994, Precision: 0.8325, Recall: 0.7994, F1: 0.7868\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 83/83 [00:13<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "Train Loss: 0.3578, Acc: 0.8638, Precision: 0.8660, Recall: 0.8638, F1: 0.8639\n",
      "Test  Loss: 0.2494, Acc: 0.9149, Precision: 0.9138, Recall: 0.9149, F1: 0.9140\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 83/83 [00:13<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "Train Loss: 0.3652, Acc: 0.8672, Precision: 0.8695, Recall: 0.8672, F1: 0.8671\n",
      "Test  Loss: 0.2936, Acc: 0.9149, Precision: 0.9204, Recall: 0.9149, F1: 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 83/83 [00:13<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "Train Loss: 0.2857, Acc: 0.8961, Precision: 0.8965, Recall: 0.8961, F1: 0.8961\n",
      "Test  Loss: 0.5219, Acc: 0.8176, Precision: 0.8701, Recall: 0.8176, F1: 0.8287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 83/83 [00:13<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "Train Loss: 0.2341, Acc: 0.9239, Precision: 0.9243, Recall: 0.9239, F1: 0.9239\n",
      "Test  Loss: 0.1851, Acc: 0.9362, Precision: 0.9414, Recall: 0.9362, F1: 0.9359\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 83/83 [00:13<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "Train Loss: 0.2125, Acc: 0.9266, Precision: 0.9271, Recall: 0.9266, F1: 0.9266\n",
      "Test  Loss: 0.1985, Acc: 0.9119, Precision: 0.9215, Recall: 0.9119, F1: 0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 83/83 [00:13<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "Train Loss: 0.1663, Acc: 0.9399, Precision: 0.9402, Recall: 0.9399, F1: 0.9398\n",
      "Test  Loss: 0.1639, Acc: 0.9453, Precision: 0.9502, Recall: 0.9453, F1: 0.9458\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 83/83 [00:13<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "Train Loss: 0.1625, Acc: 0.9433, Precision: 0.9438, Recall: 0.9433, F1: 0.9433\n",
      "Test  Loss: 0.1647, Acc: 0.9514, Precision: 0.9524, Recall: 0.9514, F1: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 83/83 [00:13<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "Train Loss: 0.1292, Acc: 0.9543, Precision: 0.9545, Recall: 0.9543, F1: 0.9543\n",
      "Test  Loss: 0.1682, Acc: 0.9422, Precision: 0.9448, Recall: 0.9422, F1: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 83/83 [00:13<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "Train Loss: 0.1301, Acc: 0.9513, Precision: 0.9513, Recall: 0.9513, F1: 0.9513\n",
      "Test  Loss: 0.1865, Acc: 0.9331, Precision: 0.9401, Recall: 0.9331, F1: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 83/83 [00:13<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "Train Loss: 0.1365, Acc: 0.9502, Precision: 0.9514, Recall: 0.9502, F1: 0.9502\n",
      "Test  Loss: 0.1712, Acc: 0.9453, Precision: 0.9486, Recall: 0.9453, F1: 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 83/83 [00:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "Train Loss: 0.1214, Acc: 0.9597, Precision: 0.9598, Recall: 0.9597, F1: 0.9597\n",
      "Test  Loss: 0.1714, Acc: 0.9362, Precision: 0.9409, Recall: 0.9362, F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 83/83 [00:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "Train Loss: 0.1383, Acc: 0.9509, Precision: 0.9514, Recall: 0.9509, F1: 0.9509\n",
      "Test  Loss: 0.1621, Acc: 0.9422, Precision: 0.9428, Recall: 0.9422, F1: 0.9421\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 83/83 [00:12<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "Train Loss: 0.1578, Acc: 0.9399, Precision: 0.9402, Recall: 0.9399, F1: 0.9399\n",
      "Test  Loss: 0.1588, Acc: 0.9514, Precision: 0.9519, Recall: 0.9514, F1: 0.9512\n",
      "Best model updated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 83/83 [00:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "Train Loss: 0.2238, Acc: 0.9224, Precision: 0.9234, Recall: 0.9224, F1: 0.9226\n",
      "Test  Loss: 0.1813, Acc: 0.9362, Precision: 0.9422, Recall: 0.9362, F1: 0.9373\n",
      "Best model saved as model_cropped_photos_radius_50.pth'\n",
      "\n",
      " Final Test Evaluation:\n",
      "Accuracy: 0.9514, Precision: 0.9519, Recall: 0.9514, F1: 0.9512\n",
      "Confusion Matrix:\n",
      " [[ 59   6   2]\n",
      " [  1 210   4]\n",
      " [  2   1  44]]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50Transfer(num_classes=3)\n",
    "trained_model = train_and_evaluate_full(model, train_loader, test_loader, \"model_cropped_photos_radius_50.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
